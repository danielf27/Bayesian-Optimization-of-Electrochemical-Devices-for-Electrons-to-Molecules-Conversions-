{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import seaborn as sn\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as ani\n",
    "from modAL.models import ActiveLearner\n",
    "import scipy.integrate as sci\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF, RationalQuadratic, Matern\n",
    "from modAL.models import ActiveLearner\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from scipy.stats import norm\n",
    "from scipy.special import ndtr\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import warnings\n",
    "from time import perf_counter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tkinter import *     # from tkinter import Tk for Python 3.x\n",
    "from tkinter.filedialog import askopenfilename\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load physics model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(LB, UB, num, dim, num_diff):\n",
    "    if num_diff == 1:\n",
    "        if dim == 2:\n",
    "            x = np.linspace(LB[0], UB[0], num)\n",
    "            y = np.linspace(LB[0], UB[0], num)\n",
    "        elif dim == 3:\n",
    "            x = np.linspace(LB[0], UB[0], num)\n",
    "            y = np.linspace(LB[0], UB[0], num)\n",
    "            w = np.linspace(LB[0], UB[0], num)\n",
    "        else:\n",
    "            x = np.linspace(LB[0], UB[0], num)\n",
    "            y = np.linspace(LB[0], UB[0], num)\n",
    "            w = np.linspace(LB[0], UB[0], num)\n",
    "            v = np.linspace(LB[0], UB[0], num)\n",
    "    elif num_diff == 2:\n",
    "        if dim == 2:\n",
    "            x = np.linspace(LB[0], UB[0], num)\n",
    "            y = np.linspace(LB[1], UB[1], num)\n",
    "        elif dim == 3:\n",
    "            x = np.linspace(LB[0], UB[0], num)\n",
    "            y = np.linspace(LB[0], UB[0], num)\n",
    "            w = np.linspace(LB[1], UB[1], num)\n",
    "        else:\n",
    "            x = np.linspace(LB[0], UB[0], num)\n",
    "            y = np.linspace(LB[0], UB[0], num)\n",
    "            w = np.linspace(LB[1], UB[1], num)\n",
    "            v = np.linspace(LB[1], UB[1], num)\n",
    "    else:\n",
    "        if dim == 3:\n",
    "            x = np.linspace(LB[0], UB[0], num)\n",
    "            y = np.linspace(LB[1], UB[1], num)\n",
    "            w = np.linspace(LB[2], UB[2], num)\n",
    "        else:\n",
    "            x = np.linspace(LB[0], UB[0], num)\n",
    "            y = np.linspace(LB[1], UB[1], num)\n",
    "            w = np.linspace(LB[2], UB[2], num)\n",
    "            v = np.linspace(LB[3], UB[3], num)\n",
    "    if dim == 2:\n",
    "        z = np.meshgrid(x, y, indexing='ij')\n",
    "        z_ = np.zeros((num**dim,dim))\n",
    "        for row in range(num**dim):\n",
    "            z_[row] = [np.ravel(z[0])[row], np.ravel(z[1])[row]]\n",
    "    elif dim == 3:\n",
    "        z = np.meshgrid(x, y, w, indexing='ij')\n",
    "        z_ = np.zeros((num**dim,dim))\n",
    "        for row in range(num**dim):\n",
    "            z_[row] = [np.ravel(z[0])[row], np.ravel(z[1])[row], np.ravel(z[2])[row]]\n",
    "    elif dim == 4:\n",
    "        z = np.meshgrid(x, y, w, v, indexing='ij')\n",
    "        z_ = np.zeros((num**dim,dim))\n",
    "        for row in range(num**dim):\n",
    "            z_[row] = [np.ravel(z[0])[row], np.ravel(z[1])[row], np.ravel(z[2])[row], np.ravel(z[3])[row]]\n",
    "    elif dim == 6:\n",
    "        z = np.meshgrid(x, x, x, x, x, x, indexing='ij')\n",
    "        z_ = np.zeros((num**dim,dim))\n",
    "        for row in range(num**dim):\n",
    "            z_[row] = [np.ravel(z[0])[row], np.ravel(z[1])[row], np.ravel(z[2])[row], np.ravel(z[3])[row], np.ravel(z[4])[row], np.ravel(z[5])[row]]\n",
    "\n",
    "    return z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_info(obj_name, info_name):\n",
    "    obj_fun_info = pd.read_csv('obj_test.csv', sep=',', header=0)\n",
    "    obj_fun_info = obj_fun_info.values\n",
    "    \n",
    "    obj_row = obj_fun_info[obj_fun_info[:,0] == obj_name,:]\n",
    "    \n",
    "    if info_name == 'dims':\n",
    "        return int(obj_row[0,1])\n",
    "    elif info_name == 'params':\n",
    "        params = obj_row[0,2].split()\n",
    "        ind = 0\n",
    "        for par in params:\n",
    "            params[ind] = float(par)\n",
    "            ind += 1\n",
    "        return params\n",
    "    elif info_name == 'param var':\n",
    "        variance = obj_row[0,3].split()\n",
    "        ind = 0\n",
    "        for var in variance:\n",
    "            variance[ind] = float(var)\n",
    "            ind += 1\n",
    "        return variance\n",
    "    elif info_name == 'num params':\n",
    "        return int(obj_row[0,4])\n",
    "    elif info_name == 'LB':\n",
    "        LB = obj_row[0,5].split()\n",
    "        ind=0\n",
    "        for L in LB:\n",
    "            LB[ind] = float(L)\n",
    "            ind += 1\n",
    "        return LB\n",
    "    elif info_name == 'UB':\n",
    "        UB = obj_row[0,6].split()\n",
    "        ind=0\n",
    "        for U in UB:\n",
    "            UB[ind] = float(U)\n",
    "            ind += 1\n",
    "        return UB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_name = 'CO2_pulse_3'\n",
    "\n",
    "dims = 3\n",
    "num = 10\n",
    "LB = get_obj_info(ob_name, 'LB')\n",
    "UB = get_obj_info(ob_name, 'UB')\n",
    "X = create_grid(LB, UB, num, dims, 3)\n",
    "X_tot = X\n",
    "first_V = X_tot[range(0,num**dims, num),:2]\n",
    "# print(np.linspace(10,1500, num=40))\n",
    "# print(np.linspace(3,4,num=40))\n",
    "\n",
    "X_tot_num = np.append(X_tot, np.zeros((len(X_tot),1)), axis=1)\n",
    "for j in range(len(X_tot_num)):\n",
    "    X_tot_num[j,3] = j\n",
    "# print(X_tot_num)\n",
    "\n",
    "# with plt.style.context('seaborn-white'):\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.scatter(data_tot[:, 0], data_tot[:, 1], c=np.ravel(data_tot[:,2]), s = 50, cmap='viridis')\n",
    "#     plt.colorbar()\n",
    "#     plt.scatter(top_data[0], top_data[1], c='k', s=200)\n",
    "#     plt.title('Physics Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get_init function\n",
    "def get_init_known(ob_name, init, dim, seed):\n",
    "\n",
    "    choices = np.zeros((int(init),dim))\n",
    "    y_choices = np.zeros((int(init),1))\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    LB = get_obj_info(ob_name, 'LB')\n",
    "    UB = get_obj_info(ob_name, 'UB')\n",
    "    for col in range(dim):\n",
    "        choices[:,col] = np.random.uniform(LB[col], UB[col], (int(init)))\n",
    "\n",
    "    choices[:,:2] = np.floor(choices[:,:2])\n",
    "    X_known = choices\n",
    "    \n",
    "    return X_known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select/input Initial experiments\n",
    "\n",
    "If this is the first time running this, you will need to randomly select the initial experiments. In this case, **use the first 2 lines of code in the section below**, and comment out the rest. You will need to provide the number of initial experiments that are desired in the *get_init_known()* function.\n",
    "\n",
    "If you already have initial experiments selected, comment out the first 2 lines of code and run the remaining part of the cell. It will ask you to input a file that contains the **X** values of the initial experiments that have already been selected. Make sure you input only the values of the initial experiments. So if you originally started with 10 initial experiments, make sure you select the file that includes only those 10 initial experiments. After choosing the file, **you need to close the small window for the code to continue running.**\n",
    "\n",
    "A graph showing the locations of the initial experiments (in 2 dimensions) will display, and a list of the initial experiments will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_num = 10\n",
    "# X_init = get_init_known(ob_name, init_num, dims, np.random.randint(1000))\n",
    "# # ob_name, init, dim, seed, params\n",
    "# X_init = X_init\n",
    "\n",
    "# Use code below if already have initial points\n",
    "\n",
    "root=Tk()\n",
    "mylabel = Label(root, text='Choose file with initial data points.')\n",
    "mylabel.pack()\n",
    "filename = askopenfilename() # show an \"Open\" dialog box and return the path to the selected file\n",
    "mainloop()\n",
    "\n",
    "X_init = pd.read_csv(filename, sep=',', header=None)\n",
    "X_init = X_init.values\n",
    "\n",
    "# X_init_ind = []\n",
    "# for exper in X_init:\n",
    "#     ind_coup = np.argwhere(X_tot == exper)\n",
    "#     X_tot_ind = [ind_coup[row,0] for row in range(0,np.size(ind_coup[:,0])-1) if np.isin(ind_coup[row,0], ind_coup[row+1:, 0])]\n",
    "#     X_init_ind = np.append(X_init_ind, X_tot_ind) \n",
    "\n",
    "\n",
    "# X_pool = np.delete(X_tot[:,:], X_init_ind.astype(int), axis=0)\n",
    "\n",
    "print(X_init)\n",
    "\n",
    "# with plt.style.context('seaborn-white'):\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.scatter(X_pool[:, 0], X_pool[:, 1], c='b', s = 200)\n",
    "#     plt.scatter(X_init[:, 0], X_init[:, 1], c='r', s = 200)\n",
    "#     plt.title('Initial Values', fontsize=20)\n",
    "#     plt.xlabel('$t_{on}$', fontsize=20)\n",
    "#     plt.ylabel('$t_{off}$', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save initial experiments\n",
    "\n",
    "If you just generated the initial experiments, you can save them as a file below. If you already have a file containing initial experiments, keep the cell below commented out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save initial experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('CO2_pulse_4D_07-18-2021.csv', X_init, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_score_ours(X_0, X_known, y_known, X_grid, regressor, params, LB, UB):\n",
    "    beta = params\n",
    "    \n",
    "    X_0 = np.reshape(X_0, (1,-1))\n",
    "    UB_arr = np.nonzero(X_0 > UB)\n",
    "    UB_arr = np.asarray(UB_arr)\n",
    "    LB_arr = np.nonzero(X_0 < LB)\n",
    "    LB_arr = np.asarray(LB_arr)\n",
    "    if UB_arr.size == 0 and LB_arr.size == 0:\n",
    "        X_0\n",
    "    elif UB_arr.size != 0:\n",
    "        X_0[0][UB_arr[1]] = (UB+LB)/2\n",
    "        if LB_arr.size != 0:\n",
    "            X_0[0][LB_arr[1]] = (UB+LB)/2\n",
    "    elif LB_arr.size != 0:\n",
    "        X_0[0][LB_arr[1]] = (UB+LB)/2\n",
    "        if UB_arr.size != 0:\n",
    "            X_0[0][UB_arr[1]] = (UB+LB)/2\n",
    "    \n",
    "    check_nan = np.isnan(X_0)\n",
    "    if sum(check_nan[0]) != 0:\n",
    "        X_0[check_nan] = (UB+LB)/2\n",
    "        \n",
    "    test_pred, std = regressor.predict(X_0, return_std=True)\n",
    "    test_pred = np.reshape(test_pred, (-1,1))\n",
    "    \n",
    "    grid_pred, grid_std = regressor.predict(X_grid, return_std=True)\n",
    "    grid_pred = np.reshape(grid_pred, (-1,1))\n",
    "    \n",
    "    distance_scores = pairwise_distances(X_0, X_known, metric='euclidean')\n",
    "    distance_scores = np.reshape(distance_scores, (1, len(X_known)))\n",
    "    c = np.amin(distance_scores)\n",
    "    \n",
    "    max_grid_val = np.amax(X_grid)\n",
    "    min_grid_val = np.amin(X_grid)\n",
    "    dist_max = 0.5*(max_grid_val - min_grid_val)\n",
    "    \n",
    "    FE = 0\n",
    "    STD = 0\n",
    "    DIST = 0\n",
    "    fe_max = np.amax(grid_pred)\n",
    "    fe_min = np.amin(grid_pred)\n",
    "    if fe_max == fe_min:\n",
    "        fe_min = np.amin(y_known)\n",
    "        fe_max = np.amax(y_known)\n",
    "    FE = (test_pred - fe_min)/(fe_max-fe_min)\n",
    "    STD = std\n",
    "    DIST = (c)/(dist_max)\n",
    "    if DIST < 0:\n",
    "        DIST = 0\n",
    "    similarity_score = 1 / (1 + DIST)\n",
    "    score = beta*(1 - similarity_score) + beta*(STD) + (FE)\n",
    "    score = np.ravel(score)\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## acquisition function definitions (daniel_query, PI, EI, UCB, Phoenics)\n",
    "class acquisition():\n",
    "    def __init__(self):\n",
    "        self.descr = 'This is an acquisition function'\n",
    "        \n",
    "    ## get_acq_fun()\n",
    "    def get_acq_fun(self, regressor,choice, X_grid, X_known, y_known, n_instances, params, LB, UB):\n",
    "        if choice == 'ours':\n",
    "            return self.ours(regressor, X_grid, X_known, y_known, n_instances, params, LB, UB)\n",
    "        elif choice == 'PI':\n",
    "            return self.PI(regressor, X_grid, X_known, y_known, n_instances, params, LB, UB)\n",
    "        elif choice == 'EI':\n",
    "            return self.EI(regressor, X_grid, X_known, y_known, n_instances, params, LB, UB)\n",
    "        elif choice == 'UCB':\n",
    "            return self.UCB(regressor, X_grid, X_known, y_known, n_instances, params, LB, UB)\n",
    "        else:\n",
    "            return 'Invalid input'\n",
    "        \n",
    "    def ours(self, regressor, X_grid, X_known, y_known, n_instances, params, LB, UB):\n",
    "        # acq, X_pool, X_known, y_known, query_number, params, ob_name\n",
    "        \n",
    "        # Create an array where we're going to put the chosen X, X_new\n",
    "        dims = X_known.shape[1]\n",
    "        beta = params\n",
    "        X_new = np.empty((0,dims))\n",
    "        bnds = Bounds(LB, UB, keep_feasible=True)\n",
    "\n",
    "        for j in range(0, n_instances):\n",
    "            \n",
    "            best_options = np.zeros((25,dims))\n",
    "            best_scores = np.zeros((25,1))\n",
    "            for k in range(0,25):\n",
    "                x0 = np.zeros((dims))\n",
    "                for col in range(dims):\n",
    "                    x0[col] = np.random.uniform(LB[col]+0.001, UB[col]-0.001)\n",
    "                res = minimize(max_score_ours, x0, args= (X_known, y_known, X_grid, regressor, params, LB, UB), method='L-BFGS-B',bounds = bnds)\n",
    "        #             lsq = least_squares(max_score_ours, x0, args = (X_known, y_known, X_grid, regressor, params), bounds =(LB,UB))\n",
    "                best_options[k] = res.x\n",
    "                best_scores[k] = res.fun\n",
    "            \n",
    "            if j == 0:\n",
    "                best_ind = np.argmin(best_scores)\n",
    "                X_new = best_options[best_ind,:]\n",
    "                X_new = np.reshape(X_new, (-1,dims))\n",
    "            else:\n",
    "                best_ind = np.argmin(best_scores)\n",
    "                X_new_ = best_options[best_ind,:]\n",
    "                X_new = np.append(X_new, X_new_)\n",
    "                X_new = np.reshape(X_new, (-1,dims))\n",
    "            \n",
    "            X_known = np.append(X_known, X_new[j])\n",
    "            X_known = np.reshape(X_known, (-1,dims))\n",
    "            X_new_now = np.reshape(X_new[j], (1,-1))\n",
    "            y_fake_new = regressor.predict(X_new_now)\n",
    "            y_fake_new = np.reshape(y_fake_new, (-1,1))\n",
    "            y_known = np.append(y_known, y_fake_new)\n",
    "            y_known = np.reshape(y_known, (-1,1))\n",
    "            regressor.fit(X_known, y_known)\n",
    "\n",
    "        return X_new, dims\n",
    "\n",
    "    def PI(self, regressor, X_grid, X_known, y_known, n_instances, params, LB, UB):\n",
    "        # self, regressor, X_grid, X_known, y_known, n_instances, params, LB, UB\n",
    "        # Create an array where we're going to put the chosen X, X_new\n",
    "        dims = X_known.shape[1]\n",
    "        tradeoff = params[3]\n",
    "        X_new = np.empty((0,dims))\n",
    "        for j in range(0, n_instances):\n",
    "            \n",
    "            x0 = np.zeros((dims))\n",
    "            for col in range(dims):\n",
    "                x0[col] = np.random.uniform(LB[col]+0.001, UB[col]-0.001)\n",
    "            lsq = least_squares(max_score_PI, x0, args = (X_known, y_known, X_grid, regressor, params), bounds =(LB,UB))\n",
    "            if j == 0:\n",
    "                X_new = lsq.x\n",
    "                X_new = np.reshape(X_new, (-1,dims))\n",
    "            else:\n",
    "                X_new = np.append(X_new, lsq.x)\n",
    "                X_new = np.reshape(X_new, (-1,dims))\n",
    "            \n",
    "            X_known = np.append(X_known, X_new[j])\n",
    "            X_known = np.reshape(X_known, (-1,dims))\n",
    "            X_new_now = np.reshape(X_new[j], (1,-1))\n",
    "            y_fake_new = regressor.predict(X_new_now)\n",
    "            y_fake_new = np.reshape(y_fake_new, (-1,1))\n",
    "            y_known = np.append(y_known, y_fake_new)\n",
    "            y_known = np.reshape(y_known, (-1,1))\n",
    "\n",
    "        return X_new, dims\n",
    "    \n",
    "    def EI(self, regressor, X_grid, X_known, y_known, n_instances, params):\n",
    "        # Create an array where we're going to put the chosen X, X_new\n",
    "        dims = X_known.shape[1]\n",
    "        tradeoff = params[3]\n",
    "        X_new = np.empty((0,dims))\n",
    "        query_idx = np.zeros((n_instances,1), dtype=np.int32)\n",
    "        for j in range(0, n_instances):\n",
    "            if j == 0:\n",
    "                lksjdfkljsd=0\n",
    "            else:\n",
    "                regressor.fit(X_known, y_known)\n",
    "            # Predict the FE for the test values\n",
    "            test_preds, std = regressor.predict(X_pool, return_std=True)\n",
    "            test_preds = np.reshape(test_preds, (-1,1))\n",
    "            std = np.reshape(std, (-1,1))\n",
    "            test_max = np.amax(test_preds)\n",
    "            scores = np.zeros(len(X_pool))\n",
    "#             for k in range(0, len(X_pool)):\n",
    "                # Need FE, std, and dist for each pool point\n",
    "            z = ndtr((test_preds - test_max - tradeoff)/std)\n",
    "            scores = (test_preds - test_max - tradeoff)*z + std*norm.pdf(z)\n",
    "                \n",
    "            query_idx[j] = np.argmax(scores)\n",
    "            # The rest of this is adding values to X_new, removing them from X_pool and making sure the X_new values have a \n",
    "            # corresponding y values\n",
    "            if j == 0:\n",
    "                X_new = X_pool[query_idx[j]]\n",
    "                X_new = np.reshape(X_new, (-1,dims))\n",
    "            else:\n",
    "                X_new = np.append(X_new, X_pool[query_idx[j]])\n",
    "                X_new = np.reshape(X_new, (-1,dims))\n",
    "            X_pool = np.delete(X_pool, query_idx[j], axis=0)\n",
    "            X_known = np.append(X_known, X_new[j])\n",
    "            X_known = np.reshape(X_known, (-1,dims))\n",
    "            X_new_now = np.reshape(X_new[j], (1,-1))\n",
    "            y_fake_new = regressor.predict(X_new_now)\n",
    "            y_fake_new = np.reshape(y_fake_new, (-1,1))\n",
    "            y_known = np.append(y_known, y_fake_new)\n",
    "            y_known = np.reshape(y_known, (-1,1))\n",
    "            for m in range(0, j):\n",
    "                if query_idx[m] < query_idx[j]:\n",
    "                    query_idx[j] = query_idx[j] + 1\n",
    "\n",
    "        return query_idx, X_new, X_pool\n",
    "    \n",
    "    def UCB(self, regressor, X_grid, X_known, y_known, n_instances, params, LB, UB):\n",
    "        # self, regressor, X_grid, X_known, y_known, n_instances, params, LB, UB\n",
    "        # Create an array where we're going to put the chosen X, X_new\n",
    "        dims = X_known.shape[1]\n",
    "        beta = params[3]\n",
    "        X_new = np.empty((0,dims))\n",
    "        for j in range(0, n_instances):\n",
    "\n",
    "            x0 = np.zeros((dims))\n",
    "            for col in range(dims):\n",
    "                x0[col] = np.random.uniform(LB[col]+0.001, UB[col]-0.001)\n",
    "            lsq = least_squares(max_score_UCB, x0, args = (X_known, y_known, X_grid, regressor, params), bounds =(LB,UB))\n",
    "            if j == 0:\n",
    "                X_new = lsq.x\n",
    "                X_new = np.reshape(X_new, (-1,dims))\n",
    "            else:\n",
    "                X_new = np.append(X_new, lsq.x)\n",
    "                X_new = np.reshape(X_new, (-1,dims))\n",
    "            \n",
    "            X_known = np.append(X_known, X_new[j])\n",
    "            X_known = np.reshape(X_known, (-1,dims))\n",
    "            X_new_now = np.reshape(X_new[j], (1,-1))\n",
    "            y_fake_new = regressor.predict(X_new_now)\n",
    "            y_fake_new = np.reshape(y_fake_new, (-1,1))\n",
    "            y_known = np.append(y_known, y_fake_new)\n",
    "            y_known = np.reshape(y_known, (-1,1))\n",
    "\n",
    "        return X_new, dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run learner method - Strip it down to only information that is needed\n",
    "def run_learner(X_grid, X_known, y_known, query_number, params, kern, acq, ob_name):\n",
    "    # orig_data, X_tot, X_used, y_used, batch, a, b, d, new_eps, kern, acq\n",
    "    \n",
    "    LB = get_obj_info(ob_name, 'LB')\n",
    "    UB = get_obj_info(ob_name, 'UB')\n",
    "    diff = np.array(UB) - np.array(LB)\n",
    "    min_diff = np.amin(diff)\n",
    "    length_scale = 0.5*diff\n",
    "    # To allow for experimental error inputs, alpha needs to be vector of errors for y_known values (I think?)\n",
    "    alpha = 1e-3\n",
    "    if kern == 'rbf':\n",
    "        kernel = RBF(length_scale=diff, length_scale_bounds=(1e-3, 2*min_diff)) \\\n",
    "                + WhiteKernel(noise_level=0.05, noise_level_bounds=(1e-3, 0.1))\n",
    "    elif kern == 'matern':\n",
    "        kernel = Matern(length_scale=0.2, length_scale_bounds=(1e-2, 2)) \\\n",
    "                + WhiteKernel(noise_level=1, noise_level_bounds=(1e-3, 1))\n",
    "    elif kern == 'rq':\n",
    "        kernel = RationalQuadratic(length_scale=0.2, length_scale_bounds=(1e-2, 2)) \\\n",
    "                + WhiteKernel(noise_level=1, noise_level_bounds=(1e-3, 1))\n",
    "        \n",
    "    acq_obj = acquisition()\n",
    "    \n",
    "    learner = ActiveLearner(\n",
    "        estimator=GaussianProcessRegressor(normalize_y=True, kernel=kernel, alpha=alpha, n_restarts_optimizer=100),\n",
    "        query_strategy=acq_obj.get_acq_fun,\n",
    "        X_training=X_known, y_training=np.ravel(y_known)) \n",
    "    dims = X_grid.shape[1]\n",
    "    tot_preds, std = learner.predict(X_grid, return_std=True) \n",
    "    tot_preds = np.ravel(tot_preds)\n",
    "\n",
    "    X_new, d = learner.query(acq, X_grid, X_known, y_known, query_number, params, LB, UB)\n",
    "    X_new = np.reshape(X_new, (-1,dims))\n",
    "\n",
    "    return X_new, tot_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_y_max(y_known):\n",
    "    y_known_max = np.zeros((len(y_known),1))\n",
    "    ind = 0\n",
    "    for val in y_known:\n",
    "        if ind == 0:\n",
    "            y_known_max[ind] = val\n",
    "            ind += 1\n",
    "        else:\n",
    "            if val > y_known_max[ind-1]:\n",
    "                y_known_max[ind] = val\n",
    "                ind += 1\n",
    "            else:\n",
    "                y_known_max[ind] = y_known_max[ind-1]\n",
    "                ind += 1\n",
    "    \n",
    "    return y_known_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up AL algorithm parameters\n",
    "\n",
    "Set the initial experiment size (already an input from before), batch size, exploration/exploitation rate (\"lim\"), and the maximum allowed number of experiments (\"tot_points\").\n",
    "\n",
    "Set the date that you are running the experiments and the special things about the experiment (e.g. type of reaction, type of AL algorithm, voltage, concentration).\n",
    "\n",
    "Have a file with a header with one row beneath it that contains the information about whether or not the use the physics model (\"phys_dec\"), the acquisition function that we're using, and the kernel that we're using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lists of initial point size and batch number size\n",
    "init_points_num = 10\n",
    "batch_size = 4\n",
    "tot_points = 50\n",
    "\n",
    "date = '2021-07-18'\n",
    "special = 'CO2_pulse_3D'\n",
    "\n",
    "alg_info = pd.read_csv('Alg_info.csv', sep=',', header=0)\n",
    "alg_info = alg_info.values[0]\n",
    "\n",
    "phys_dec = alg_info[0]\n",
    "acq = alg_info[1]\n",
    "kern = alg_info[2]\n",
    "\n",
    "tot_batches = np.floor((tot_points - init_points_num)/batch_size).astype(int)\n",
    "pars = np.linspace(1,0.05,tot_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Active Learning algorithm\n",
    "\n",
    "Before running the first batch of AL, you need to have already completed the initial experiments and have a file containing the **X** values and the corresponding **y** values. You will be asked to input this file. After choosing the file, **you need to close the small window for the code to continue running.**\n",
    "\n",
    "If you have already run one or more batches and you want to stop running this program, that is okay. When you start this program again, you need to execute each of the cells like you did the first time (taking note of the initial experiments part). Then when you come to this cell, input the data that you have for all the experiments. For example, if you had 10 initial experiments and the batch size was 3, and then you ran 2 batches of AL, you would have data for 16 experiments. You would input the data for those 16 experiments and **the code below will calculate which batch number you are on.**\n",
    "\n",
    "After you input the data, it will run AL. It will save the prediction values as a csv file and the experiment data with the new experiments as a csv. The experiment data file can be opened and used to add the data for the new experiments. A graph should appear showing what the predictions looked like, the locations of the physics points, the locations of the known experimental points, and the locations of the new selected experiments.\n",
    "\n",
    "After this, it will ask if you want to continue. If you type **\"Y\"**, then a new batch will start by asking you for the input of the experimental data. If you would rather stop the program and start it again once you have run the experiments, type **\"N\"** and the *for* loop will stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=Tk()\n",
    "# Tk().withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "label = Label(root, text='Choose file containing experiment data.')\n",
    "label.pack()\n",
    "filename = askopenfilename() # show an \"Open\" dialog box and return the path to the selected file\n",
    "mainloop()\n",
    "\n",
    "data_init = pd.read_csv(filename, sep=',', header=None)\n",
    "data_init = data_init.values\n",
    "X_known = data_init[:,:dims].astype(int)\n",
    "y_known = data_init[:,dims]\n",
    "\n",
    "if phys_dec == 0:\n",
    "    pass\n",
    "elif phys_dec == 1:\n",
    "    x0 = params\n",
    "    temp, params = non_lin(fun, x0, X_known, y_known, obj_fun_name) \n",
    "\n",
    "exp_num = len(X_known)\n",
    "curr_batch = int((exp_num-init_points_num)/batch_size)\n",
    "\n",
    "np.savetxt('Phys_params_%s_batch_%s_%s.csv' % (special, curr_batch, date), pars, delimiter=',')\n",
    "\n",
    "max_val = np.amax(y_known)\n",
    "min_val = np.amin(y_known)\n",
    "\n",
    "# phys_vals = phys_tot[:,2]*(max_val-min_val) + min_val\n",
    "\n",
    "max_vals = np.array([max_val])\n",
    "max_locs = np.array(X_known[np.argmax(y_known), :])\n",
    "\n",
    "for j in range(curr_batch, tot_batches):\n",
    "    if phys_dec == 0:\n",
    "        pass\n",
    "    elif phys_dec == 1:\n",
    "        X_used, y_used = get_used_data(X_known, y_known, ob_name, tot_points, params)\n",
    "        # X_known, y_known, ob_name, num, params\n",
    "        X_used = np.reshape(X_used, (-1,dims))\n",
    "        y_used = np.reshape(y_used, (-1,1))\n",
    "    \n",
    "    par = pars[j]\n",
    "    \n",
    "    if phys_dec == 0:\n",
    "        X_new, tot_preds = run_learner(X_tot, X_known, y_known, batch_size, par,kern, acq, ob_name)\n",
    "        # X_grid, X_known, y_known, query_number, a, b, d, eps, kern, acq, ob_name\n",
    "    elif phys_dec == 1:\n",
    "        X_new, tot_preds = run_learner(X_tot, X_used, y_used, batch_size, par, kern, acq, ob_name)\n",
    "    \n",
    "    print(X_new)\n",
    "    \n",
    "    np.savetxt('tot_preds_%s_batch_%s_%s.csv' % (special, j, date), tot_preds, delimiter=',')\n",
    "#     np.savetxt('tot_std_%s_batch_%s_%s.csv' % (special, j, date), std, delimiter=',')\n",
    "    exp_data = np.concatenate((X_known,np.reshape(y_known, (-1,1))), axis=1)\n",
    "    exp_data = np.concatenate((exp_data,np.zeros((batch_size,dims+1))))\n",
    "    exp_data[-batch_size:,:dims] = np.reshape(X_new, (-1,dims))\n",
    "    np.savetxt('Experiment_data_%s_batch_%s_%s.csv' % (special, j, date), exp_data, delimiter=',')\n",
    "    \n",
    "    max_loc = np.argmax(tot_preds)\n",
    "    print(X_tot[max_loc])\n",
    "    min_val = np.amin(tot_preds)\n",
    "    max_val = np.amax(tot_preds)\n",
    "    with plt.style.context('seaborn-white'):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.scatter(X_tot[range(10,num**dims, num),0], X_tot[range(10,num**dims, num),1], c=tot_preds[range(10,num**dims, num)], s = 200, cmap = 'viridis', vmin=min_val, vmax=max_val)\n",
    "#         plt.scatter(X_used[:, 0], X_used[:, 1], c='k', s = 100)\n",
    "#         plt.scatter(X_tot[X_new_ind.astype(int), 0], X_tot[X_new_ind.astype(int), 1], c='r', s = 100)\n",
    "        plt.scatter(X_known[:, 0], X_known[:, 1], c=np.ravel(y_known), s = 150, cmap = 'viridis', vmin=min_val, vmax=max_val)\n",
    "        plt.colorbar()\n",
    "        plt.scatter(X_new[:, 0], X_new[:, 1], c='b', s=200)\n",
    "        plt.title('Predictions and Choices', fontsize=20)\n",
    "        plt.show()\n",
    "    \n",
    "    exit_val = 0\n",
    "    count = 1\n",
    "    while (exit_val == 0):\n",
    "        Cont = input('Do you want to continue? (Y/N): ')\n",
    "        if Cont == 'Y':\n",
    "            X_known = np.append(X_known, X_new)\n",
    "            X_known = np.reshape(X_known, (-1,dims))\n",
    "            \n",
    "            root=Tk()\n",
    "            label = Label(root, text='Choose file containing old y values and new y values.')\n",
    "            label.pack()\n",
    "            filename = askopenfilename() # show an \"Open\" dialog box and return the path to the selected file\n",
    "            mainloop()\n",
    "        \n",
    "            data = pd.read_csv(filename, sep=',', header=None)\n",
    "            data = data.values\n",
    "            y_known = data[:,dims]\n",
    "            y_known = np.reshape(y_known, (-1,1))\n",
    "            \n",
    "            if phys_dec == 0:\n",
    "                pass\n",
    "            elif phys_dec == 1:\n",
    "                x0 = params\n",
    "                temp, params = non_lin(fun, x0, X_known, y_known, obj_fun_name) \n",
    "                np.savetxt('Phys_params_%s_batch_%s_%s.csv' % (special, curr_batch+1, date), pars, delimiter=',')\n",
    "            count += 1\n",
    "            exit_val = 1\n",
    "        elif Cont == 'N':\n",
    "            break\n",
    "        else:\n",
    "            Cont = input('Invalid input!')\n",
    "    \n",
    "    \n",
    "    y_known_max = calc_y_max(y_known)\n",
    "    \n",
    "    with plt.style.context('seaborn-white'):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(np.arange(0,len(y_known_max)), y_known_max, linewidth=3, color = 'blue')\n",
    "        plt.xlabel('Number of Experiments', fontsize=20)\n",
    "        plt.ylabel('y value', fontsize=20)\n",
    "        plt.title('Max y value after every experiment', fontsize=20)\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.tick_params(direction='in', length=10,width=2)\n",
    "        plt.savefig('y_value_%s_batch_%s_%s.png' % (special, j, date), transparent=True)\n",
    "    \n",
    "    if Cont == 'N':\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results\n",
    "\n",
    "The following blocks of code were used to plot the results from the BO experiments in various ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Experiment_data_CO2_pulse_3D_production_rate_2021-07-13.csv', sep=',', header=None)\n",
    "# data = pd.read_csv('3D_opt_FE.csv', sep=',', header=None)\n",
    "data = data.values\n",
    "\n",
    "y_known = data[:,5]\n",
    "\n",
    "y_known_max = calc_y_max(y_known)\n",
    "\n",
    "with plt.style.context('seaborn-white'):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(np.arange(0,len(y_known_max)), y_known_max, linewidth=3, color = 'blue')\n",
    "    plt.scatter(np.arange(0,len(y_known_max)), np.ravel(y_known), c='black', s=50)\n",
    "    plt.xlabel('Number of Experiments', fontsize=30)\n",
    "    plt.ylabel('CO Partial Current Density [$mA$ $cm^{-2}$]', fontsize=30)\n",
    "#     plt.title('3D CO production optimization', fontsize=25)\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.tick_params(direction='in', length=10,width=2)\n",
    "#     plt.savefig('y_value_%s_batch_%s_%s.png' % (special, j, date), transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot_data = pd.read_csv('tot_preds_CO2_pulse_3D_batch_9_2021-07-13.csv', sep=',', header=None)\n",
    "# tot_data = tot_data.values\n",
    "\n",
    "\n",
    "kern = 'rbf'\n",
    "\n",
    "LB = get_obj_info(ob_name, 'LB')\n",
    "UB = get_obj_info(ob_name, 'UB')\n",
    "diff = np.array(UB) - np.array(LB)\n",
    "min_diff = np.amin(diff)\n",
    "length_scale = 0.5*diff\n",
    "# To allow for experimental error inputs, alpha needs to be vector of errors for y_known values (I think?)\n",
    "alpha = 1e-3\n",
    "if kern == 'rbf':\n",
    "    kernel = RBF(length_scale=length_scale, length_scale_bounds=(1e-3,2*min_diff)) \\\n",
    "            + WhiteKernel(noise_level=0.01, noise_level_bounds=(1e-3, 1))\n",
    "elif kern == 'matern':\n",
    "    kernel = Matern(length_scale=0.2, length_scale_bounds=(1e-2, 2)) \\\n",
    "            + WhiteKernel(noise_level=1, noise_level_bounds=(1e-3, 1))\n",
    "elif kern == 'rq':\n",
    "    kernel = RationalQuadratic(length_scale=0.2, length_scale_bounds=(1e-2, 2)) \\\n",
    "            + WhiteKernel(noise_level=1, noise_level_bounds=(1e-3, 1))\n",
    "\n",
    "acq_obj = acquisition()\n",
    "\n",
    "learner = ActiveLearner(\n",
    "    estimator=GaussianProcessRegressor(normalize_y=False, kernel=kernel, alpha=alpha, n_restarts_optimizer=100),\n",
    "    query_strategy=acq_obj.get_acq_fun,\n",
    "    X_training=data[:,:3], y_training=np.ravel(data[:,5])) \n",
    "dims = X_tot.shape[1]\n",
    "tot_preds, std = learner.predict(X_tot[:,:3], return_std=True) \n",
    "tot_preds = np.ravel(tot_preds)\n",
    "ind_data = np.argmax(tot_preds)\n",
    "# print(X_tot[ind_data,:])\n",
    "# print(np.amax(tot_preds))\n",
    "# resting_curr = X_tot[ind_data,3]\n",
    "# acting_curr= X_tot[ind_data,2]\n",
    "# rest_time = X_tot[ind_data,1]\n",
    "# act_time = X_tot[ind_data,0]\n",
    "\n",
    "# rest_vals = np.linspace(0,75,40)\n",
    "# mid_val = curr_vals[9]\n",
    "# time_vals = np.linspace(10,1500,20)\n",
    "\n",
    "X_0 = X_tot[X_tot[:,2]==300]\n",
    "inds_0 = X_tot_num[X_tot[:,2]==300][:,3]\n",
    "# X_25 = X_tot[X_tot[:,2]==300]\n",
    "# inds_25 = X_tot_num[X_tot[:,2]==300][:,3]\n",
    "# X_50 = X_tot[X_tot[:,2]==50]\n",
    "# inds_50 = X_tot_num[X_tot[:,2]==50][:,3]\n",
    "# X_75 = X_tot[X_tot[:,2]==75]\n",
    "# inds_75 = X_tot_num[X_tot[:,2]==75][:,3]\n",
    "loc = np.argmax(tot_preds[inds_0.astype(int)])\n",
    "print(X_0[loc,:])\n",
    "\n",
    "print(np.amax(tot_preds[inds_0.astype(int)]))\n",
    "\n",
    "# X_slice_1 = X_0[X_0[:,0]==act_time]\n",
    "# inds_slice_1 = inds_0[X_0[:,0]==act_time]\n",
    "\n",
    "# X_slice_2 = X_0[X_0[:,1]==rest_time]\n",
    "# inds_slice_2 = inds_0[X_0[:,1]==rest_time]\n",
    "\n",
    "# X_slice_3 = X_0[X_0[:,2]==acting_curr]\n",
    "# inds_slice_3 = inds_0[X_0[:,2]==acting_curr]\n",
    "\n",
    "\n",
    "# max_0 = np.amax(tot_preds[inds_slice_1.astype(int)])\n",
    "# max_25 = np.amax(tot_preds[inds_slice_2.astype(int)])\n",
    "# max_50 = np.amax(tot_preds[inds_slice_3.astype(int)])\n",
    "# max_val = np.amax([max_0, max_25, max_50])\n",
    "\n",
    "# min_0 = np.amin(tot_preds[inds_slice_1.astype(int)])\n",
    "# min_25 = np.amin(tot_preds[inds_slice_2.astype(int)])\n",
    "# min_50 = np.amin(tot_preds[inds_slice_3.astype(int)])\n",
    "# min_val = np.amin([min_0, min_25, min_50])\n",
    "\n",
    "# std_norm = (std-min_val)/(max_val-min_val)\n",
    "\n",
    "PiYGBig = cm.get_cmap('magma', 512)\n",
    "newcmp = ListedColormap(PiYGBig(np.linspace(0, 0.7, 256)))\n",
    "\n",
    "with plt.style.context('seaborn-white'):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax1 = ax.scatter(data[:,1], data[:,0], data[:,2], c=np.ravel(data[:,5]), s = 500, cmap = 'viridis')\n",
    "    cb = fig.colorbar(ax1, shrink=.75, pad=0.1)\n",
    "    cb.ax.tick_params(labelsize=25)\n",
    "    cb.set_label(label='CO Partial Current Density [$mA$ $cm^{-2}$]', size=25)\n",
    "#     plt.colorbar()\n",
    "#     plt.scatter(X_used[:, 0], X_used[:, 1], c='k', s = 100)\n",
    "#     plt.scatter(X_tot[X_new_ind.astype(int), 0], X_tot[X_new_ind.astype(int), 1], c='r', s = 100)\n",
    "#     ax2 = ax.scatter(data[:, 0], data[:, 1], data[:,2],c=data[:,3], s = 200, cmap = 'winter')\n",
    "#     fig.colorbar(ax2, shrink=.75, pad=0.15, label='Resting current density [mA/c$m^2$]')\n",
    "#     plt.colorbar()\n",
    "#     plt.scatter(X_slice_3[:, 0], X_slice_3[:, 1], c=np.ravel(tot_preds[inds_slice_3.astype(int)]), s=300, cmap = 'plasma', vmin=min_val, vmax=max_val)\n",
    "#     plt.scatter(X_tot[:, 0], X_tot[:, 1], c=np.ravel(tot_preds), s=300, cmap = 'plasma')\n",
    "#     cb = plt.colorbar()\n",
    "#     cb.ax.tick_params(labelsize=30)\n",
    "#     ax.set_xlim(1500,0)\n",
    "    plt.xticks(ticks=(0, 500, 1000, 1500), fontsize=25)\n",
    "    plt.yticks(ticks=(1500, 1000, 500, 0), fontsize=25)\n",
    "    ax.set_zticks(ticks=(100, 150, 200, 250, 300))\n",
    "#     plt.xticks(fontsize=30, rotation=45)\n",
    "#     plt.yticks(fontsize=30)\n",
    "    for tick in ax.zaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(25)  \n",
    "\n",
    "    ax.set_xlabel('$t_{rest}$ [ms]', fontsize=25, labelpad=15)\n",
    "    ax.set_xlim(1500, 0)\n",
    "    ax.set_ylabel('$t_{act}$ [ms]', fontsize=25, labelpad=15)\n",
    "#     plt.xlabel('$t_{act}$ [ms]', fontsize=30)\n",
    "#     plt.ylabel('$t_{rest}$ [ms]', fontsize=30)\n",
    "#     plt.ylabel('$j_{act}$ [$mA$ $cm^{-2}$]', fontsize=30)\n",
    "    plt.tick_params(direction='in', length=10,width=2)\n",
    "#     plt.xlim((-5,1505))\n",
    "#     plt.ylim((-5,1505))\n",
    "#     plt.ylabel('Resting time [ms]', fontsize=20)\n",
    "    ax.set_zlabel('$j_{act}$ [$mA$ $cm^{-2}$]', fontsize=25, labelpad=15)\n",
    "#     plt.title('4D Experimental Points', fontsize=25)\n",
    "#     plt.title('(A) CO Faradaic Efficiency at 100 $mA$ $cm^{-2}$', fontsize=25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.read_csv('4D_opt_points_1_5_20210718-20.csv', sep=',', header=None)\n",
    "points = points.values\n",
    "\n",
    "points_1 = np.mean(points[:,0])\n",
    "points_1_std = np.std(points[:,0])\n",
    "\n",
    "points_5 = np.mean(points[:,1])\n",
    "points_5_std = np.std(points[:,1])\n",
    "\n",
    "with plt.style.context('seaborn-white'):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.bar([0,1], [points_1,points_5], width=.8, yerr=[points_1_std,points_5_std], tick_label=['Point 1', 'Point 5'])\n",
    "    plt.xlabel('Design point', fontsize=20)\n",
    "    plt.ylabel('Normalized CO production', fontsize=20)\n",
    "    plt.title('Average CO production (n=12)', fontsize=20)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.tick_params(direction='in', length=10,width=2)\n",
    "#     plt.savefig('y_value_%s_batch_%s_%s.png' % (special, j, date), transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
